{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karinayang454/Twitter_Sentiment_Analysis/blob/main/TwitterSentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wztN76NpyZn",
        "outputId": "973bb4e5-3101-4e7c-d15c-e4f3efb13bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/CAIS/WinterProject\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# change to correct directory\n",
        "%cd /content/drive/My Drive/CAIS/WinterProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQMuQr9l1L2z",
        "outputId": "c68b37d4-91b9-4b76-efee-be910764e3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwkZQJXdwv14",
        "outputId": "bc16da65-a67c-4abd-ca99-1a8ad36bdfce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras import layers\n",
        "from keras.optimizers import *\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6zUR3SlbxTv7",
        "outputId": "0f07e799-10d0-4507-aced-89f9b90f8f65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-13411db0-cedc-4a57-863c-45bac4893dc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Need a hug</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@Tatiana_K nope they didn't have it</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@twittera que me muera ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13411db0-cedc-4a57-863c-45bac4893dc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13411db0-cedc-4a57-863c-45bac4893dc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13411db0-cedc-4a57-863c-45bac4893dc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet  valence\n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...        0\n",
              "1  is upset that he can't update his Facebook by ...        0\n",
              "2  @Kenichan I dived many times for the ball. Man...        0\n",
              "3    my whole body feels itchy and like its on fire         0\n",
              "4  @nationwideclass no, it's not behaving at all....        0\n",
              "5                      @Kwesidei not the whole crew         0\n",
              "6                                        Need a hug         0\n",
              "7  @LOLTrish hey  long time no see! Yes.. Rains a...        0\n",
              "8               @Tatiana_K nope they didn't have it         0\n",
              "9                          @twittera que me muera ?         0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# read in data\n",
        "STORE_PATH = '/content/drive/MyDrive/CAIS/WinterProject/'\n",
        "df=pd.read_csv(STORE_PATH + 'data.csv')\n",
        "df = df[['tweet','valence']] # drop column: \"author\"\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59XVrxhVBW7v"
      },
      "outputs": [],
      "source": [
        "# few notes about the dataset\n",
        "# df['valence'].unique()               0 and 4\n",
        "# len(df)                              1.6 million\n",
        "# df.groupby('valence').count()        0: 8 million, 4: 8 million\n",
        "# df.groupby('valence').nunique()        #about 1-3k repeats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clnNc6oO2dGp"
      },
      "outputs": [],
      "source": [
        "# function to clean the data\n",
        "def depure_data(data): \n",
        "    # Removing URLs with a regular expression\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    data = url_pattern.sub(r'', data)\n",
        "    # Remove Emails\n",
        "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
        "    # Remove new line characters\n",
        "    data = re.sub('\\s+', ' ', data)\n",
        "    # # Remove distracting single quotes\n",
        "    data = re.sub(\"\\'\", \"\", data)\n",
        "        \n",
        "    return data\n",
        "\n",
        "\n",
        "# further preprocess the tweets\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence),     deacc=True))\n",
        "\n",
        "# detokenize text\n",
        "def detokenize(text):\n",
        "    return TreebankWordDetokenizer().detokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohihVnYfG-Jf"
      },
      "outputs": [],
      "source": [
        "temp = []\n",
        "data_to_list = df['tweet'].values.tolist()\n",
        "for i in range(len(data_to_list)):\n",
        "    temp.append(depure_data(data_to_list[i]))\n",
        "data_words = list(sent_to_words(temp))\n",
        "print(data_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3QEodvbKREG",
        "outputId": "e12b9f48-9016-40ba-b576-74f95049ca02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['awww that bummer you shoulda got david carr of third day to do it', 'is upset that he can update his facebook by texting it and might cry as result school today also blah', 'dived many times for the ball managed to save the rest go out of bounds', 'my whole body feels itchy and like its on fire', 'no it not behaving at all mad why am here because can see you all over there', 'not the whole crew', 'need hug', 'hey long time no see yes rains bit only bit lol fine thanks how you', 'nope they didn have it', 'que me muera']\n",
            "193\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "for i in range(len(data_words)):\n",
        "    data.append(detokenize(data_words[i]))\n",
        "print(data[:10])\n",
        "longest_string=max(data,key=len)\n",
        "print(len(longest_string)) # 193 is max length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "FGGDo2PNM6hT",
        "outputId": "e8fa0b4e-3923-4fae-853c-37f10959533b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ed691412898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#convert range of values from {0,4} to {0,1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "data = np.array(data)\n",
        "# convert range of values from {0,4} to {0,1}\n",
        "labels = np.array(df['valence']//4)\n",
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UckOOzr5OVe4",
        "outputId": "45f13279-231b-4581-8eed-acd2792ee231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ...    1   38    4]\n",
            " [   0    0    0 ...   37  256 1092]\n",
            " [   0    0    0 ...   35   30   10]\n",
            " ...\n",
            " [   0    0    0 ...   13    9 1988]\n",
            " [   0    0    0 ...   10 4954   48]\n",
            " [   0    0    0 ...    0    0  113]]\n"
          ]
        }
      ],
      "source": [
        "max_words = 7000\n",
        "max_len = 195\n",
        "\n",
        "# convert tweets to word embeddings\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data)\n",
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR9g8MjsZ751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6645ba9b-649f-4a3b-d5f6-c56ff5d08b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "960000 640000 960000 640000\n"
          ]
        }
      ],
      "source": [
        "# split data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, train_size=0.6,random_state=0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIZb6PoSaY5R",
        "outputId": "f63c10bf-a032-4ad3-9e0a-807fd08e69fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 203s 413ms/step - loss: 0.4797 - binary_accuracy: 0.7675 - val_loss: 0.4375 - val_binary_accuracy: 0.7974\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 192s 410ms/step - loss: 0.4345 - binary_accuracy: 0.7976 - val_loss: 0.4250 - val_binary_accuracy: 0.8024\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 192s 409ms/step - loss: 0.4234 - binary_accuracy: 0.8033 - val_loss: 0.4186 - val_binary_accuracy: 0.8062\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 192s 409ms/step - loss: 0.4158 - binary_accuracy: 0.8076 - val_loss: 0.4150 - val_binary_accuracy: 0.8091\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 191s 408ms/step - loss: 0.4102 - binary_accuracy: 0.8111 - val_loss: 0.4115 - val_binary_accuracy: 0.8115\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 191s 408ms/step - loss: 0.4052 - binary_accuracy: 0.8139 - val_loss: 0.4097 - val_binary_accuracy: 0.8120\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 192s 409ms/step - loss: 0.4013 - binary_accuracy: 0.8162 - val_loss: 0.4081 - val_binary_accuracy: 0.8133\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 192s 409ms/step - loss: 0.3981 - binary_accuracy: 0.8180 - val_loss: 0.4076 - val_binary_accuracy: 0.8142\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 192s 409ms/step - loss: 0.3954 - binary_accuracy: 0.8192 - val_loss: 0.4061 - val_binary_accuracy: 0.8147\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 191s 408ms/step - loss: 0.3927 - binary_accuracy: 0.8206 - val_loss: 0.4070 - val_binary_accuracy: 0.8143\n"
          ]
        }
      ],
      "source": [
        "# Bidirectional model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model.add(layers.Bidirectional(layers.LSTM(20,return_sequences=True, input_shape=(None,40),dropout=0.3)))\n",
        "model.add(layers.Bidirectional(layers.LSTM(40,dropout=0.6)))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=2048, validation_data=(X_test, y_test),shuffle=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TwitterSentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvoaMeBrw6YumRd/czhO6S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}